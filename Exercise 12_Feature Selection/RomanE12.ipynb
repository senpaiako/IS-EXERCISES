{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection Exercie\n",
    "\n",
    "In this exercise, we will apply Feature Selection to a Iris flowers dataset, where the target variable is the Species. Essentially, our goal is to identify the features that are most relevant in discerning the species of each Iris flower. The dataset is from: https://www.kaggle.com/datasets/uciml/iris\n",
    "\n",
    "1. Load the dataset from the exercise's Github Repository (Iris.csv)\n",
    "2. Using buisness logic/common sense, drop features that are surely irrevelvant to the target variable.\n",
    "3. Preprocess your data (split data into training and testing)\n",
    "4. Apply feature selection with the following methods:\n",
    "    - Pearson's correlation coefficient (r)\n",
    "    - Kendall's tau (τ)\n",
    "    - Mutual Information (MI)\n",
    "    - Logistic Regression with L1 penalty\n",
    "6. Compare the results of each feature selection method:\n",
    "    - What features did you manually dropped before applying the feature selection methods? Explain why.\n",
    "    - Are there any common features selected across multiple methods?\n",
    "    - Can you explain why certain features were selected based on their characteristics?\n",
    "(Optional) Visualize the importance of features using techniques like bar charts or heatmaps to make it easier to compare.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries\n",
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, mutual_info_classif\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from scipy.stats import pearsonr, kendalltau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Id  SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm FlowerColour  \\\n",
      "0   1            5.1           3.5            1.4           0.2       Purple   \n",
      "1   2            4.9           3.0            1.4           0.2       Orange   \n",
      "2   3            4.7           3.2            1.3           0.2        Black   \n",
      "3   4            4.6           3.1            1.5           0.2        White   \n",
      "4   5            5.0           3.6            1.4           0.2         Teal   \n",
      "\n",
      "   YearCollected  MonthCollected  StigmaLegnth      Species  \n",
      "0           2003               2             2  Iris-setosa  \n",
      "1           1998               9             1  Iris-setosa  \n",
      "2           1995               5             3  Iris-setosa  \n",
      "3           2008               3             3  Iris-setosa  \n",
      "4           2007               9             1  Iris-setosa  \n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "iris_df = pd.read_csv(\"Iris.csv\")\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "print(iris_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "irrelevant_features = ['Id', 'FlowerColour', 'YearCollected']\n",
    "iris_df = iris_df.drop(irrelevant_features, axis=1)\n",
    "\n",
    "# Separate features (X) and target variable (y)\n",
    "X = iris_df.drop('Species', axis=1)\n",
    "y = iris_df['Species']\n",
    "\n",
    "# Preprocess the data: split into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 1: Pearson's correlation coefficient (r)\n",
    "correlation_scores, _ = pearsonr(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 2: Kendall's tau (τ)\n",
    "tau_scores, _ = kendalltau(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 3: Mutual Information (MI)\n",
    "mi_selector = SelectKBest(mutual_info_classif, k='all')\n",
    "mi_selector.fit(X_train, y_train)\n",
    "mi_scores = mi_selector.scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 4: Logistic Regression with L1 penalty\n",
    "logreg = LogisticRegression(penalty='l1', solver='liblinear')\n",
    "logreg.fit(X_train, y_train)\n",
    "l1_selector = SelectFromModel(logreg, prefit=True)\n",
    "l1_support = l1_selector.get_support()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare the results\n",
    "feature_selection_results = pd.DataFrame({\n",
    "    'Feature': X_train.columns,\n",
    "    'Pearson_Correlation': correlation_scores,\n",
    "    'Kendall_Tau': tau_scores,\n",
    "    'Mutual_Information': mi_scores,\n",
    "    'L1_Penalty': l1_support\n",
    "})\n",
    "\n",
    "# Display the results\n",
    "print(feature_selection_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
